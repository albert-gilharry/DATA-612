{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 612 Project 5: Implementing a Recommender System on Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to gain hands on experience of building a recommender using Apache Spark. Apache Spark is an open-source distributed cluster computing framework with that facilitates in-memory computation with less reliance on the disk storage. Making it one of the most widely used framework for big data processing in both the academic and industry setting.\n",
    "\n",
    "I am using the Jester data set 1 from [http://eigentaste.berkeley.edu/dataset/] (that I have used on previous projects) for this project. The data set contains anonymous ratings from 24,983 users who have rated 36 or more jokes. The Ratings are real values ranging from -10.00 to +10.00. The selected subset of the data contains 2,498,300 ratings with missing ratings denoted with the number 99, making it in an ideal data set to utilize on the Spark framework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import  SparkSession\n",
    "from pyspark.ml.feature import IDF, Tokenizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is separated into two data sets, a text/csv file that contains the ratings for each joke the users and a directory of html files where each file contains the content for a given joke. We will now connet to a local Spark instance and load these data into Spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(joke_id=1, text='\\nA man visits the doctor. The doctor says \"I have bad news for you.You have\\ncancer and Alzheimer\\'s disease\". <P>\\nThe man replies \"Well,thank God I don\\'t have cancer!\"\\n'),\n",
       " Row(joke_id=2, text='\\nThis couple had an excellent relationship going until one day he came home\\nfrom work to find his girlfriend packing. He asked her why she was leaving him\\nand she told him that she had heard awful things about him. \\n<P>\\n\"What could they possibly have said to make you move out?\" \\n<P>\\n\"They told me that you were a pedophile.\" \\n<P>\\nHe replied, \"That\\'s an awfully big word for a ten year old.\" \\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize lists to store texts for each joke and their IDs\n",
    "jokes = []\n",
    "joke_ids = list(range(1,101))\n",
    "\n",
    "# load each html file and extract the text\n",
    "for i in range(0,100):\n",
    "    joke_text = open(\"data/jokes/init\"+str((i+1))+\".html\", \"r\") \n",
    "    a = joke_text.read()\n",
    "    joke=a[a.find(\"-->\")+3:a.find(\"<!--end\")]\n",
    "    jokes.append(joke)\n",
    "    joke_text.close()\n",
    "    \n",
    "# use intermediate pandas dataframe\n",
    "jokes_df = pd.DataFrame()\n",
    "jokes_df['joke_id'] = joke_ids\n",
    "jokes_df['text'] = jokes\n",
    "\n",
    "\n",
    "# Create a spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# load jokes into spark\n",
    "spark_jokes_df = spark.createDataFrame(jokes_df)\n",
    "spark_jokes_df.createOrReplaceTempView('spark_jokes_df')\n",
    "spark_jokes_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows the first two jokes in row format that was loaded from the HTML files. Now let's load the ratings into Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+-----+-----+-----+\n",
      "|_c0|  _c1|  _c2|  _c3|  _c4|  _c5|\n",
      "+---+-----+-----+-----+-----+-----+\n",
      "| 74|-7.82| 8.79|-9.66|-8.16|-7.52|\n",
      "|100| 4.08|-0.29| 6.36| 4.37|-2.38|\n",
      "| 49|   99|   99|   99|   99| 9.03|\n",
      "| 48|   99| 8.35|   99|   99|  1.8|\n",
      "| 91|  8.5| 4.61|-4.17|-5.39| 1.36|\n",
      "|100|-6.17|-3.54| 0.44| -8.5|-7.09|\n",
      "| 47|   99|   99|   99|   99| 8.59|\n",
      "|100| 6.84| 3.16| 9.17|-6.21|-8.16|\n",
      "|100|-3.79|-3.54|-9.42|-6.89|-8.74|\n",
      "| 72| 3.01| 5.15| 5.15| 3.01| 6.41|\n",
      "+---+-----+-----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load user interactions and ratings\n",
    "spark_interactions = spark.read.csv(\"data/jester-data-1.csv\")\n",
    "spark_interactions.createOrReplaceTempView('spark_interactions')\n",
    "\n",
    "# cache dataframe for later use\n",
    "spark_interactions.cache()\n",
    "\n",
    "# preview data\n",
    "spark_interactions.select('_c0','_c1','_c2','_c3','_c4','_c5').show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows the first 10 rows and 6 columns of the ratings dataframe in Spark. Each row represents a user, the first column is number of jokes that the user rated and the each subsequent column represents the ratings for a specific joke. The output below shows that both data sets have been loaded into Spark and thus building the recommender may proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='spark_interactions', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='spark_jokes_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Based Filtering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have previously used SVD and other approaches on these data but will be taking a different approach for this project. I have yet to build a Content-Based recommender on this data set so I will take this opportunity to do so. As a reminder, content-based recommenders uses descriptions of items the user has interacted with and recommends them similar items with which they have not interacted. I will be building the item profiles using the text for each joke by applying TF-IDF transformation to get the most important terms in each joke. I will then build user profiles my taking an average of the item profiles the user has interacted with. To make a recommendation a user's profile will be compared to the profiles of items he/she has not yet rated, and the jokes that are most similar to the user's profile will be recommended. Similarity will determined based on the Cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Item Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>0.552911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0.233094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>0.338454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p&gt;</td>\n",
       "      <td>0.456237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "0            0.000000\n",
       "1     the    0.552911\n",
       "2       a    0.233094\n",
       "3     and    0.338454\n",
       "4      to    0.000000\n",
       "5     <p>    0.456237\n",
       "6      of    0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform each joke content into an array of words\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(spark_jokes_df)\n",
    "\n",
    "# calculate the frequency of each work in each document\n",
    "countVectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\").fit(wordsData)\n",
    "featurizedData = countVectorizer.transform(wordsData)\n",
    "\n",
    "# now calculate the TF-IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "# cache matrix\n",
    "rescaledData.cache()\n",
    "\n",
    "# create preview\n",
    "df = pd.DataFrame( {'feature' : countVectorizer.vocabulary, 'importance' : rescaledData.collect()[0]['features'].toArray()} )\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows a part of the item profile for the first joke. It shows the a sample of the terms and their importance. Now the user profiles will be created by averaging the item profiles that the user has rated before. We will need to load the interactions for a given user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>0.022241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0.017553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>0.019630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>0.022089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p&gt;</td>\n",
       "      <td>0.014297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>0.023257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>you</td>\n",
       "      <td>0.021652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>0.023165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he</td>\n",
       "      <td>0.032403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words  importance\n",
       "0          0.000000\n",
       "1   the    0.022241\n",
       "2     a    0.017553\n",
       "3   and    0.019630\n",
       "4    to    0.022089\n",
       "5   <p>    0.014297\n",
       "6    of    0.023257\n",
       "7   you    0.021652\n",
       "8    in    0.023165\n",
       "9    he    0.032403"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to load items the user has rated\n",
    "def getUserInteractions(user_id):\n",
    "    \n",
    "    # extract items the user has rated\n",
    "    user_interactions = [ key for (key,value) in spark_interactions.collect()[user_id].asDict().items() if value != '99' ]\n",
    "    user_interactions = [ int(i.replace(\"_c\", \"\")) for i in user_interactions ]\n",
    "    \n",
    "    # ignore and remove references to the first column, it is not needed here\n",
    "    if user_interactions[0] == 0:\n",
    "        user_interactions.pop(0)\n",
    "    return user_interactions\n",
    "\n",
    "# average the item profiles for a given user\n",
    "def createUserProfile(user_interactions):\n",
    "    user_profile = np.zeros(len(countVectorizer.vocabulary))\n",
    "    for i in user_interactions:\n",
    "        user_profile = user_profile + rescaledData.collect()[i-1]['features'].toArray()\n",
    "    \n",
    "    user_profile = user_profile/len(countVectorizer.vocabulary)\n",
    "    return user_profile\n",
    "\n",
    "# select a user at random to demonstrate\n",
    "user_id = 567\n",
    "user_interactions = getUserInteractions(user_id)\n",
    "user_profile = createUserProfile(user_interactions)\n",
    "\n",
    "# preview the profile\n",
    "user_profile_df = pd.DataFrame()\n",
    "user_profile_df['words'] = countVectorizer.vocabulary\n",
    "user_profile_df['importance'] = user_profile\n",
    "user_profile_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output below shows a portion of the user 567's profile. Now let's provide this user with a recommendation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Recommendataions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Cosine similarity to recommend jokes the user haven't rated before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76</td>\n",
       "      <td>0.201211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>93</td>\n",
       "      <td>0.173483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>91</td>\n",
       "      <td>0.162182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>92</td>\n",
       "      <td>0.141980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>97</td>\n",
       "      <td>0.138308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    joke_id  similarity\n",
       "5        76    0.201211\n",
       "19       93    0.173483\n",
       "17       91    0.162182\n",
       "18       92    0.141980\n",
       "23       97    0.138308"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to provide recommendations for a given user\n",
    "def makeRecommendations(user_profile):\n",
    "    # inilize lists for recommendation\n",
    "    recommendations = []\n",
    "    joke = []\n",
    "    \n",
    "    # calculate similarity of items profiles not yet rated to the user profile\n",
    "    for i in range(1,100):\n",
    "        if i not in user_interactions:\n",
    "            similarity = cosine_similarity(user_profile.reshape(1, -1),\n",
    "                                       rescaledData.collect()[i-1]['features'].toArray().reshape(1,-1))\n",
    "            recommendations.append(similarity[0][0])\n",
    "            joke.append(i)\n",
    "            \n",
    "    # for viewing purposes return a data frame\n",
    "    recommendations_df = pd.DataFrame()\n",
    "    recommendations_df['joke_id'] = joke\n",
    "    recommendations_df['similarity'] = recommendations\n",
    "    recommendations_df.sort_values(by='similarity', inplace=True, ascending=False)\n",
    "    \n",
    "    return recommendations_df\n",
    "#.sort_values(by=['similarity'], inplace=True, ascending=False)\n",
    "recommendations = makeRecommendations(user_profile)\n",
    "recommendations.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that based on the user's content, user 567 would probably like jokes 76, 93, 91, 92, and 97."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with text data is generally more computionally expensive than working with numbers because they usually require more memory and disk storage and cannot be indexed as simple as numeric values. Hence, this project provided a good use-case for utilizing Spark in memory processing. The benefits of Spark will shine as more users rate jokes and more jokes are added to the system. In an online environment, the main issue of this system will be to dynamically update user profiles and item profiles without sacrificing user experience. This makes Spark one of the best solution for this problem. I chose PySpark over R because of the ability to build a complete web experience for this solution. I will be presenting my web application for this recommender for my Data Science in Context Presentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
